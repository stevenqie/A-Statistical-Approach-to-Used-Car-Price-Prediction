---
title: "A Statistical Approach to Used Car Price Prediction"
output: pdf_document
date: 12/09/2024
header-includes:
  - \usepackage{multicol}
  - \usepackage{fancyvrb}
  - \setlength{\columnsep}{1cm}
  - \usepackage{geometry}
  - \geometry{margin=1in}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\begin{multicols}{3}
\setlength{\columnsep}{2pt}

\begin{center}
\textbf{Steven Qie} \\
\textit{Statistics and Computer Science} \\
\textit{University of Illinois Urbana-Champaign} \\
\textbf{qie2@illinois.edu}
\end{center}

\columnbreak

\begin{center}
\textbf{Brian Gong} \\
\textit{Statistics and Computer Science} \\
\textit{University of Illinois Urbana-Champaign} 
\textbf{brianhg2@illinois.edu}
\end{center}

\columnbreak

\begin{center}
\textbf{William Yeh} \\
\textit{Statistics and Computer Science} \\
\textit{University of Illinois Urbana-Champaign} 
\textbf{wy16@illinois.edu}
\end{center}

\end{multicols}

## Introduction

With the used car market being significantly larger than the new car market, many consumers are realizing that used cars provide a more affordable option. It plays a significant role in the growth and stability of the U.S. economy, driven by changing consumer preferences, economic factors, and the availability of certain cars. Accurately predicting the price of a used car is a challenging but essential task for buyers, sellers, and market analysts/economists alike. 

This report aims to develop various predictive models for used car prices using the Used Car Price Prediction Dataset from Kaggle. This dataset comprises of 4,009 data points, representing unique vehicle listings, as well as nine distinct features that serve as key indicators influencing the value of a used car. We follow a very structured and standard approach, including data exploration, preprocessing, model training, and evaluation using relevant performance metrics. By leveraging these methods, we aim to uncover valuable insights into the world of automobiles and the various factors that are driving used car prices.

Need a section on key findings....



Abstractâ€” 

white space 

white space 

white space 

white space 

white space 

white space 

white space 

white space 

white space 

We utilized AI tools in this report to enhance and assist in our writing. These tools helped play a big role in ensuring clarity, conciseness, and professionalism. We also utilized AI tools to help us with syntax help when writing code in R, as well as discovering potential bugs in our code. 


## Literature Review 
This literature review aims to summarize key findings and approaches from a few noteworthy research papers focused on used car price prediction. 

"Price Prediction of Used Cars Using Machine Learning", written by Chuyang Jin of the University of Sydney, presents a model that can predict a used vehicle's price given their year of production, mileage, tax, miles per gallon, He hopes that his model can benefit and save time for both sellers and buyers who are looking to sell or serach for second-hand vehicles. Jin used a CSV dataset containing 100,000 records of used cars in the UK, focusing specifically on the Mercedes brand. The nine factors that he considered were the following: model, year, selling price, transmission, mileage, fuel type, tax, miles per gallon (mpg), and engine size. While doing exploratory data analysis and preprocessing, Jin noted that many many predictors had skewed distributions. For example, the overwhelming majority of prices fell in the 0-75,000 range, limiting the model's potential effectiveness for higher price ranges. Jin deemed these data points as outliers and excluded them to ensure that the model would be more accurate and usable. After testing various forms of regression, namely linear, polynomial, SVR, Decision Trees, and Random Forests, Jin found Random Forest Regression yielded the best R squared value of 0.90416. 

"Used Car Price Prediction using Machine Learning: A Case Study", written by Mustapha Hankar, Marouane Birjali, and Abderrahim Beni-Hssane, applies several supervised machine learning algorithms to predict used car price prices based on features from a dataset collected from an online eCommerce website called Avito. During preprocessing, the authors of this paper performed recursive feature elimination to maintain only the most relevant features to car prices: year of manufacture, mileage, mark, fuel type, fiscal power, and model. Along with a baseline multiple linear regression model, the study also looked at K-nearest neighbors, Random Forest, Gradient Boosting, and Artificial Neural Networks. The study utilized 2 different performance metrics, R^2 and RMSE, and concluded that the Gradient Boosting Regression Model achieved the best results, with a R^2 of 0.8 and RMSE of 44516.20. 

"Car Price Prediction using Supervised and Unsupervised Learning Models and Deep Learning" by Thomas Nsiah approached the problem of car price prediction from a supervised and unsupervised lenses. While supervised models allow a consumer to understand the key factors and predictors that influence pricing of used cars, unsupervised learning oftentimes uncovers hidden connections and patterns within the data. In his paper, Nsiah used a mock dataset of 50,000 UK second hand car sales with features similar to the previous 2 studies, such as model, engine size, fuel type, year, and mileage. Supervised learning models that Nsiah tried included simple linear regression, polynomial regression, and random forest, evaluated using mean absolute error (MAE) and R-squared metrics. He concluded that out of the supervised models, random forest performed best with an R-squared of 0.99849 and a MAE of 289.0691. For unsupervised learning techniques, Nsiah applied K-Means and DBSCAN clustering to identify price patterns, evaluated using the Davis Boudlin Index and the Silhouette Coefficient. He concluded that K-Means clustering for the year of manufacture vs price produced the best clustering results.

Overall, these three studies demonstrate the effectiveness that machinie learning can have on accurately predicting used car prices. The next section will outline our own approach and findings.

Citations: 

- C. Jin, "Price Prediction of Used Cars Using Machine Learning," in 2021 IEEE International Conference on Emergency Science and Information Technology (ICESIT), Chongqing, China, 2021, pp. 223-230, doi: 10.1109/ICESIT53460.2021.9696839.
- M. Hankar, M. Birjali, and A. Beni-Hssane, "Used Car Price Prediction using Machine Learning: A Case Study," in 2022 11th International Symposium on Signal, Image, Video and Communications (ISIVC), El Jadida, Morocco, 2022, pp. 1-4, doi: 10.1109/ISIVC54825.2022.9800719.
- T. Nsiah, "Car Price Prediction using Supervised and Unsupervised Learning Models and Deep Learning," unpublished, 2024.


## Data Processing and Summary Statistics 

First, we will import the dataset and libraries into our workspace 
```{r}
library(caret)
library(ggplot2)
library(MASS)
library(randomForest)
library(kernlab)
library(stringr)
library(glmnet)
data <- read.csv("used_cars.csv")
```

Quick overview of data
```{r}
head(data)
na_values <- data[!complete.cases(data), ]
cat("NA Values:", nrow(na_values), "\n")
empty_space_rows <-  data[rowSums(data == "", na.rm = TRUE) > 0, ]
cat("Empty Values:", nrow(empty_space_rows), "\n")
data[data == ""] <- NA
```
Just looking at the data, some notable columns to do some preprocessing is accident,engine. Price and mileage can use some preprocessing to make into a number. Also, milage is spelled wrong. Although there seems to be no NA values, a lot of rows of clean_title are notably empty. Other cols like fuel_type and accident also contain some empty values. We turned empty values into NA values.


```{r}
cat(unique(data$accident), "\n")
data$accident <- ifelse(data$accident == "At least 1 accident or damage reported", 1, 0)

cat(unique(data$clean_title), "\n")
data$clean_title <-ifelse(data$clean_title == "Yes", 1, 0)
data$clean_title[is.na(data$clean_title)] <- 0
head(data)
```
Because accident only has 2 unique values, no accidents and 1 or more accidents, we changed it to 1,0 to be useful for models. We apply similar reasoning to clean_title. Since there is only "Yes" and NA, we treat all the yes's to 1 and all the NA values to 0.
```{r}
head(data$engine, 5)

# Extract Horsepower (HP)
data$horsepower <- as.numeric(str_extract(data$engine, "\\d+\\.\\d+(?=HP)"))

# Extract Displacement
data$displacement <- as.numeric(str_extract(data$engine, "\\d+\\.\\d+(?=L)"))

# Extract Cylinders
data$cylinders <- str_extract(data$engine, "\\d+ Cylinder")

data$cylinders_numeric <- as.numeric(str_extract(data$cylinders, "\\d+"))

# Extract Engine Type
data$engine_type <- str_extract(data$engine, "DOHC|SOHC|Turbo|Twin Turbo|Electric Motor")

# Extract Fuel Type
data$fuel_type <- str_extract(data$engine, "Gasoline|Diesel|Electric|Hybrid|Flex Fuel|Plug-In Electric/Gas")

# factor fuel type
data$fuel_type_factor <- factor(data$fuel_type)
data$fuel_type_numeric <- as.numeric(data$fuel_type_factor)
```

```{r}
cat(head(data$price, 5), "\n")
data$price <- as.numeric(gsub("[$,]", "", data$price))
```
Removed the dollar sign and comma in price to enable numeric operations

```{r}
colnames(data)[colnames(data) == "milage"] <- "mileage"
data$mileage <- as.numeric(gsub("[,]| mi\\.", "", data$mileage))
```
Updated the name of milage column to -> mileage. Removed mi. and , to enable numeric operations

```{r}
empty_space_rows <-  data[rowSums(data == "", na.rm = TRUE) > 0, ]
cat("Empty Values:", nrow(empty_space_rows), "\n")
```

#summary statistics
```{r}
summary(data)
```

## numeric data

```{r}
datan <- data[c("model_year", "mileage", "accident", "clean_title", "horsepower", "displacement", "cylinders_numeric", "fuel_type_numeric", "price")]
summary(datan)
colSums(is.na(datan))
```
## pca 

```{r}
# remove null values
data_cleaned <- na.omit(datan) # almost 1000
head(data_cleaned)
dim(data_cleaned)

# remove price response var
clean_no_price <- within(data_cleaned, rm("price"))
head(clean_no_price)
dim(clean_no_price)

# scale 
data_scaled <- scale(clean_no_price)
# pca fit, try princomp or prcomp
pcafit <- princomp(clean_no_price)
pcafit

scores <- pcafit$scores

scores

plot(scores[, 1], scores[, 2], 
     xlab = "Principal Component 1", 
     ylab = "Principal Component 2", 
     main = "PCA: First Two Components",
     col = "blue", pch = 20)

# pca_result <- prcomp(clean_no_price, center = TRUE, scale. = TRUE)

```

## Unsupervised Learning 
Apply at least three clustering algorithms to the processed dataset.
Determine the appropriate number of clusters and discuss the interpretability of these clusters. Do they hold any meaningful distinctions?
Examine whether the clustering results are associated with your outcome variable.

1. KMeans Clustering 
```{r}
data_subset <- data[, c("model_year", "price")]
data_subset <- na.omit(data_subset)
data <- scale(data_subset)
```
We decided to use kmeans to examine the relation between model_year and price, as we noticed a similar examination in one of the papers while doing the literature review

```{r}

library(cluster)
set.seed(1)
# Compute silhouette scores for k = 2 to 10
sil_scores <- sapply(2:10, function(k) {
  km <- kmeans(scale(data_subset[, c("model_year", "price")]), centers = k, nstart = 10)
  silhouette(km$cluster, dist(scale(data_subset[, c("model_year", "price")]))) %>%
    summary() %>%
    .$avg.width
})
# Plot silhouette scores
plot(2:10, sil_scores, type = "b", pch = 19, frame = FALSE,
     xlab = "Number of Clusters (k)",
     ylab = "Average Silhouette Score",
     main = "Silhouette Method for Optimal k")

```


```{r}
library(ggplot2)
set.seed(1)  


kmeans_result <- kmeans(data_subset_scaled, centers = 4)

# Add cluster assignments to the original data
data_subset$cluster <- as.factor(kmeans_result$cluster)

# Visualize the clusters
ggplot(data_subset, aes(x = model_year, y = price, color = cluster)) +
  geom_point(size = 2) +
  labs(title = "K-Means Clustering on Model Year vs Price",
       x = "Model Year",
       y = "Price") +
  theme_minimal()


```
Two notable things:
1. There are a couple huge outliers in the price department that is taking up its own cluster
2.The rest of the clusters (2,3,4) are clearly separated by year ranges. There is a slightly higher range/variation in price in the most recent year range, so there may be a weak relationship between a more recent model_year and higher price



2. Hierarchical Clustering 

Next, we will try hierarchical clustering with three different linkage methods(single, complete, and average) using euclidean distance. Hierarchical Clustering begins with each data point starting as its own cluster. The goal is to progressively group them together until there is only one group. The process involves choosing the closest two groups, calculated through a specific distance metric. 
```{r}
library(stats)
set.seed(1)
numeric_data <- data[, sapply(data, is.numeric)]
numeric_data_without_price <- numeric_data[, !colnames(numeric_data) %in% "price"]

hclust_single <- hclust(dist(numeric_data_without_price, method = "euclidean"), method = "single")
hclust_complete <- hclust(dist(numeric_data_without_price, method = "euclidean"), method = "complete")
hclust_average <- hclust(dist(numeric_data_without_price, method = "euclidean"), method = "average")

par(mfrow = c(1, 3))
plot(hclust_single, main = "Single Linkage", xlab = "", sub = "", cex = 0.6)
plot(hclust_complete, main = "Complete Linkage", xlab = "", sub = "", cex = 0.6)
plot(hclust_average, main = "Average Linkage", xlab = "", sub = "", cex = 0.6)
par(mfrow = c(1, 1))

```

```{r}

clusters_complete <- cutree(hclust_complete, k = 4)


data$cluster <- as.factor(clusters_complete)


table(data$cluster)
library(dplyr)

cluster_summary <- data %>%
  group_by(cluster) %>%
  summarise(
    avg_price = mean(price, na.rm = TRUE),
    avg_model_year = mean(model_year, na.rm = TRUE),
    avg_accident = mean(as.numeric(accident), na.rm = TRUE),  # Replace with proper numeric conversion if needed
    avg_mileage = mean(mileage, na.rm = TRUE),
    avg_horsepower = mean(horsepower, na.rm = TRUE),
    count = n()
  )

# Print the cluster summary
print(cluster_summary)


```


3. Spectral Clustering 

Finally, we will try spectral clustering, which aims to group observations based on their proximity information. This method involves 2 main steps, the first being using the eigenvalues of a similarity matrix to perform dimension reduction, followed by applying a clustering algorithm like K-means. 

```{r}
set.seed(1)
specc_result <- specc(as.matrix(train[, -1]), centers = 3, kernel = "rbfdot")
```


## Prediction Models 

For all the supervised models below, we will split the data into training sets for model training and testing sets to evaluate performance and accuracy
```{r}
y = data$price
X = data.matrix(cbind(1, data[, setdiff(names(data), "price")]))
test_idx = sample(nrow(data), size = 0.2 * nrow(data))
trainx = X[ -test_idx, ]
testx  = X[ test_idx, ]
trainy = y[ -test_idx ]
testy  = y[ test_idx ]
```

1. Linear Model. There are mainly three possible linear models: Lasso, Ridge, and Elastic Net. We will try all three models and see which one performs the best. Lasso, Ridge, and Elastic Net all benefit from feature scaling because these models involve regularization. which will penalize the size of coefficients of the model to avoid overfitting. All 3 models also involving a tuning parameter, and so we will use k-fold cross validation to find the best parameters. 

```{r}
set.seed(1)
#feature scale the data 
xtrain_scaled <- scale(xtrain_copy)  # Scale the training feature data
xtest_scaled <- scale(xtest_copy, center = attr(xtrain_scaled, "scaled:center"), 
                      scale = attr(xtrain_scaled, "scaled:scale"))  # Apply same scaling to test data
```

Setup for Kfold Cross Validation 
```{r}
train_control <- trainControl(method = "cv", number = 10)  # 10-fold cross-validation
# For Lasso (alpha = 1)
lasso_grid <- expand.grid(alpha = 1, lambda = seq(0.01, 1, by = 0.01))

# For Ridge (alpha = 0)
ridge_grid <- expand.grid(alpha = 0, lambda = seq(0.01, 1, by = 0.01))

# For Elastic Net (alpha between 0 and 1)
elastic_net_grid <- expand.grid(alpha = seq(0, 1, by = 0.1), lambda = seq(0.01, 1, by = 0.01))
```

Training our 3 models 
```{r}
lasso_model <- train(x = Xtrain, y = ytrain, method = "glmnet",
                     trControl = train_control, tuneGrid = lasso_grid)

ridge_model <- train(x = Xtrain, y = ytrain, method = "glmnet",
                     trControl = train_control, tuneGrid = ridge_grid)

elastic_net_model <- train(x = Xtrain, y = ytrain, method = "glmnet", trControl = train_control, tuneGrid = elastic_net_grid)

```

Finding the best tuning parameters for all of them 
```{r}
print(paste("Best tuning parameter for Lasso: ", lasso_model$bestTune))
print(paste("Best tuning parameters for Ridge:", ridge_model$bestTune))
print(paste("Best tuning parameters for Elastic Net:", elastic_net_model$bestTune))
```

Predict on our test set and find prediction error 
```{r}
lasso_pred <- predict(lasso_model, Xtest)
ridge_pred <- predict(ridge_model, Xtest)
elastic_net_pred <- predict(elastic_net_model, Xtest)

print(paste("Lasso model prediction error:", mean((lasso_pred - ytest)^2)))
print(paste("Ridge model prediction error:", mean((ridge_pred - ytest)^2)))
print(paste("Elastic net prediction error: ", mean((elastic_net_pred - ytest)^2)))
```
Out of our 3 linear models, ... performed the best 


2. K Nearest Neighbors(KNN) regression works by calculating the k nearest training set data points to the test point and predicting the target value by taking the average of their target values. KNN is sensitive to feature scaling, so we will need to scale the data. The reason behind this is for example, if one feature has ranges from 1-10 and another one has 1-10000, distance calcualtions will be biased and results will suffer as a result. KNN is also sensitive to the choice of k. To find the optimal value of k, we will perform k-fold cross validation. 

```{r}
# feature scale- scale only the numerical columns 
scaled_data = copy(as.data.table(data))
numerical_cols <- sapply(scaled_data, is.numeric)
scaled_data[numerical_cols] <- scale(scaled_data[numerical_cols])
```

```{r}
#use scaled data 
#train knn algorithm and perform k fold cross validation
control <- trainControl(method = "cv", number = 10)
knn.cvfit <- train(y ~ ., method = "knn", 
                     data = data.frame(xtrain_scaled, ytrain,
                     tuneGrid = data.frame(k = seq(1, 40, 1)),
                     trControl = control)
# Plot the cross-validation results to visualize performance
plot(knn_model)

#plot k vs regression error 
plot(knn.cvfit$results$k, 1-knn.cvfit$results$Accuracy,
     xlab = "K", ylab = "Classification Error", type = "b",
     pch = 19, col = "darkorange")

print(paste("The best value of k based on cross-validation is: ", knn_model$bestTune))
```

```{r}
# Train the final model using the best value of k and find the predictions
best_k <- knn_model$bestTune$k
knn_predictions <- knn(train = xtrain_scaled, test = xtest_scaled, cl = ytrain, k = best_k)

# Calculate prediction error 
print(paste("Prediction errort: ", mean((as.numeric(knn_predictions) - ytest)^2)))
```


3. Random Forest 
```{r}
rf_model <- randomForest(train_labels ~ ., data = as.data.frame(train_data))

rf_predictions <- predict(rf_model, newdata = as.data.frame(test_data))
```
4. SVM? does this count as a linear model 
5. Gradient Boosting Regressor 

## Open-Ended Question/Conclusion
A researcher is interested in estimating the original price of the cars in your dataset as if they were brand new. 

Several challenges arise from this approach. 


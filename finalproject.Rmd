---
title: "A Statistical Approach to Used Car Price Prediction"
output: pdf_document
date: 12/09/2024
header-includes:
  - \usepackage{multicol}
  - \usepackage{fancyvrb}
  - \setlength{\columnsep}{1cm}
  - \usepackage{geometry}
  - \geometry{margin=1in}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\begin{multicols}{3}
\setlength{\columnsep}{2pt}

\begin{center}
\textbf{Steven Qie} \\
\textit{Statistics and Computer Science} \\
\textit{University of Illinois Urbana-Champaign} \\
\textbf{qie2@illinois.edu}
\end{center}

\columnbreak

\begin{center}
\textbf{Brian Gong} \\
\textit{Statistics and Computer Science} \\
\textit{University of Illinois Urbana-Champaign} 
\textbf{brianhg2@illinois.edu}
\end{center}

\columnbreak

\begin{center}
\textbf{William Yeh} \\
\textit{Statistics and Computer Science} \\
\textit{University of Illinois Urbana-Champaign} 
\textbf{wy16@illinois.edu}
\end{center}

\end{multicols}

## Introduction

With the used car market being significantly larger than the new car market, many consumers are realizing that used cars provide a more affordable option. It plays a significant role in the growth and stability of the U.S. economy, driven by changing consumer preferences, economic factors, and the availability of certain cars. Accurately predicting the price of a used car is a challenging but essential task for buyers, sellers, and market analysts/economists alike. 

This report aims to develop various predictive models for used car prices using the Used Car Price Prediction Dataset from Kaggle. This dataset comprises of 4,009 data points, representing unique vehicle listings, as well as nine distinct features that serve as key indicators influencing the value of a used car. We follow a very structured and standard approach, including data exploration, preprocessing, model training, and evaluation using relevant performance metrics. By leveraging these methods, we aim to uncover valuable insights into the world of automobiles and the various factors that are driving used car prices.

Need a section on key findings....



Abstractâ€” 

white space 

white space 

white space 

white space 

white space 

white space 

white space 

white space 

white space 

We utilized AI tools in this report to enhance and assist in our writing. These tools helped play a big role in ensuring clarity, conciseness, and professionalism. We also utilized AI tools to help us with syntax help when writing code in R, as well as discovering potential bugs in our code. 


## Literature Review 
This literature review aims to summarize key findings and approaches from a few noteworthy research papers focused on used car price prediction. 

"Price Prediction of Used Cars Using Machine Learning", written by Chuyang Jin of the University of Sydney, presents a model that can predict a used vehicle's price given their year of production, mileage, tax, miles per gallon, He hopes that his model can benefit and save time for both sellers and buyers who are looking to sell or serach for second-hand vehicles. Jin used a CSV dataset containing 100,000 records of used cars in the UK, focusing specifically on the Mercedes brand. The nine factors that he considered were the following: model, year, selling price, transmission, mileage, fuel type, tax, miles per gallon (mpg), and engine size. While doing exploratory data analysis and preprocessing, Jin noted that many many predictors had skewed distributions. For example, the overwhelming majority of prices fell in the 0-75,000 range, limiting the model's potential effectiveness for higher price ranges. Jin deemed these data points as outliers and excluded them to ensure that the model would be more accurate and usable. After testing various forms of regression, namely linear, polynomial, SVR, Decision Trees, and Random Forests, Jin found Random Forest Regression yielded the best R squared value of 0.90416. 

"Used Car Price Prediction using Machine Learning: A Case Study", written by Mustapha Hankar, Marouane Birjali, and Abderrahim Beni-Hssane, applies several supervised machine learning algorithms to predict used car price prices based on features from a dataset collected from an online eCommerce website called Avito. During preprocessing, the authors of this paper performed recursive feature elimination to maintain only the most relevant features to car prices: year of manufacture, mileage, mark, fuel type, fiscal power, and model. Along with a baseline multiple linear regression model, the study also looked at K-nearest neighbors, Random Forest, Gradient Boosting, and Artificial Neural Networks. The study utilized 2 different performance metrics, R^2 and RMSE, and concluded that the Gradient Boosting Regression Model achieved the best results, with a R^2 of 0.8 and RMSE of 44516.20. 

"Car Price Prediction using Supervised and Unsupervised Learning Models and Deep Learning" by Thomas Nsiah approached the problem of car price prediction from a supervised and unsupervised lenses. While supervised models allow a consumer to understand the key factors and predictors that influence pricing of used cars, unsupervised learning oftentimes uncovers hidden connections and patterns within the data. In his paper, Nsiah used a mock dataset of 50,000 UK second hand car sales with features similar to the previous 2 studies, such as model, engine size, fuel type, year, and mileage. Supervised learning models that Nsiah tried included simple linear regression, polynomial regression, and random forest, evaluated using mean absolute error (MAE) and R-squared metrics. He concluded that out of the supervised models, random forest performed best with an R-squared of 0.99849 and a MAE of 289.0691. For unsupervised learning techniques, Nsiah applied K-Means and DBSCAN clustering to identify price patterns, evaluated using the Davis Boudlin Index and the Silhouette Coefficient. He concluded that K-Means clustering for the year of manufacture vs price produced the best clustering results.

Overall, these three studies demonstrate the effectiveness that machinie learning can have on accurately predicting used car prices. The next section will outline our own approach and findings.

Citations: 

- C. Jin, "Price Prediction of Used Cars Using Machine Learning," in 2021 IEEE International Conference on Emergency Science and Information Technology (ICESIT), Chongqing, China, 2021, pp. 223-230, doi: 10.1109/ICESIT53460.2021.9696839.
- M. Hankar, M. Birjali, and A. Beni-Hssane, "Used Car Price Prediction using Machine Learning: A Case Study," in 2022 11th International Symposium on Signal, Image, Video and Communications (ISIVC), El Jadida, Morocco, 2022, pp. 1-4, doi: 10.1109/ISIVC54825.2022.9800719.
- T. Nsiah, "Car Price Prediction using Supervised and Unsupervised Learning Models and Deep Learning," unpublished, 2024.


## Data Processing and Summary Statistics 

First, we will import the dataset and libraries into our workspace 
```{r}
library(caret)
library(ggplot2)
library(MASS)
library(randomForest)
library(kernlab)
library(stringr)
library(cluster)
library(glmnet)
library(stats)
library(dplyr)
library(class)
data <- read.csv("used_cars.csv")
```

#Preliminary Data Cleaning/Modifications
First, we will removed the dollar sign and comma in price to enable numeric operations
```{r}
#cat(head(data$price, 5), "\n")
data$price <- as.numeric(gsub("[$,]", "", data$price))
```

The Engine columns contains very useful information such as the horsepower, displacement, cylinders, engine type, and fuel type. We turn these all into new columns. 
```{r}
#head(data$engine, 5)

# Extract Horsepower (HP)
#data$horsepower <- as.numeric(str_extract(data$engine, "\\d+\\.\\d+(?=HP)"))

# Extract Displacement
#data$displacement <- as.numeric(str_extract(data$engine, "\\d+\\.\\d+(?=L)"))

# Extract Cylinders
#data$cylinders <- str_extract(data$engine, "\\d+ Cylinder")

#data$cylinders_numeric <- as.numeric(str_extract(data$cylinders, "\\d+"))

# Extract Engine Type
#data$engine_type <- str_extract(data$engine, "DOHC|SOHC|Turbo|Twin Turbo|Electric Motor")

# Extract Fuel Type
#data$fuel_type <- str_extract(data$engine, "Gasoline|Diesel|Electric|Hybrid|Flex Fuel|Plug-In Electric/Gas")

# factor fuel type
#data$fuel_type_factor <- factor(data$fuel_type)
#data$fuel_type_numeric <- as.numeric(data$fuel_type_factor)

#deleting the engine column because we have extracted all the information 
#data$engine = NULL
#colnames(data)
```

Corrected the spelling of mileage from milage to mileage. Removed mi. and , to enable numeric operations
```{r}
colnames(data)[colnames(data) == "milage"] <- "mileage"
data$mileage <- as.numeric(gsub("[,]| mi\\.", "", data$mileage))
```


#Analyzing Null/Empty Values 
We will first look at the problem with NA and Empty values, something that this dataset has a lot of. We will first handle both NA and Empty "" values by replacing them to "NA" to make it easier to preprocess and analyze.  
```{r}
na_columns <- colSums(is.na(data)) > 0
empty_string_columns <- colSums(data == "") > 0
columns_with_na_or_empty <- na_columns | empty_string_columns
print(names(data)[columns_with_na_or_empty])

data[data == "" | is.na(data)] <- "NA"
```
There are three columns with empty strings/NA values. Let's examine all three of them to discover if we can find any patterns. 

```{r}
result <- data %>%
  group_by(fuel_type) %>%
  summarise(
    medianprice = median(price),
    averageprice = mean(price),
    count = n()
  )
print(result)
```
The NA values for fuel_type have a higher median price and average price than other types, and makes up a significant count of observations so we are going to treat it as a separate category.

```{r}
result <- data %>%
  group_by(accident) %>%
  summarise(
    medianprice = median(price),
    averageprice = mean(price),
    count = n()
  )
print(result)
```
The NA/Empty values for accident exhibit very similar properties to the None reported category, with median price and average price being pretty similar, not to mention a very small percentage of data is represented by this value. Therefore, we replace and combine these observations with the None reported category. Because accident only has 2 unique values now, no accidents and 1 or more accidents, we changed it to 1,0 to be useful for models. 
```{r}
data$accident[data$accident == "NA"] <- "None reported"
#unique(data$accident)
data$accident <- ifelse(data$accident == "At least 1 accident or damage reported", 1, 0)
#unique(data$accident)
```

```{r}
result <- data %>%
  group_by(clean_title) %>%
  summarise(
    medianprice = median(price),
    averageprice = mean(price),
    count = n()
  )
print(result)
```

The NA values for clean_title clearly have a significantly higher median price and will be treated as a separate category. We apply similar reasoning from accident to clean_title. Since there is only "Yes" and NA, we treat all the yes's to 1 and all the NA values to 0.
```{r}
data$clean_title <-ifelse(data$clean_title == "Yes", 1, 0)
unique(data$clean_title)
```

#Removing Outliers 
```{r}
Q1 <- quantile(data$price, 0.25, na.rm = TRUE)
Q3 <- quantile(data$price, 0.75, na.rm = TRUE)
IQR_value <- IQR(data$price, na.rm = TRUE)

# Identify outliers using IQR
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

outliers <- data[data$price < lower_bound | data$price > upper_bound, ]
print(paste("Number of outliers: ", nrow(outliers), "and average price of these cars: ", round(mean(outliers$price), 2)))
      
#removing these rows from the dataset
data <- data[!(data$price < lower_bound | data$price > upper_bound), ]
```

#need feature identification and analysis for categorical and numerical variables 
#One hot encoding for our categorical variables 
```{r}
data[] <- lapply(data, function(x) {
  if (is.character(x) || is.logical(x)) {
    as.factor(x)
  } else {
    x
  }
})
str(data)
```

#Final Summary Statistics
```{r}
summary(data)
head(data)
```

## Prediction Models 

For all the supervised models below, we will split the data into training sets for model training and testing sets to evaluate performance and accuracy
```{r}
#head(data)
y = data$price
X = data[, -ncol(data)]
#test_idx = sample(nrow(data), size = 0.2 * nrow(data))
#xtrain = X[ -test_idx, ]
#xtest  = X[ test_idx, ]
#ytrain = y[ -test_idx ]
#ytest  = y[ test_idx ]

sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.8, 0.2))
xtrain <- X[sample, ]
xtest <- X[!sample, ]
ytrain = y[sample]
ytest = y[!sample] 

#as.matrix(xtrain)
#sum(is.na(xtrain)
colnames(xtrain)
```

1. Linear Model. There are mainly three possible linear models: Lasso, Ridge, and Elastic Net. We will try all three models and see which one performs the best. Lasso, Ridge, and Elastic Net all benefit from feature scaling because these models involve regularization. which will penalize the size of coefficients of the model to avoid overfitting. All 3 models also involving a tuning parameter, and so we will use k-fold cross validation to find the best parameters. 
APPLY ONE HOT ENCODING 

```{r}
#apply one hot encoding first 
xtrain <- model.matrix(~ . - 1, data = xtrain)
```

Training our ridge model 
```{r}
xtrain <- model.matrix(~ . - 1, data = xtrain)
ridgemodel = cv.glmnet(x = xtrain, y = ytrain, nfolds = 10, alpha = 0)

```

```{r}
ridgemodel$lambda.min

pred1 = predict(ridgemodel, newx = xtest, s = "lambda.min")
sqrt(mean((pred1 - ytest)^2))
```

Training our lasso model 
```{r}
lassomodel = cv.glmnet(x = xtrain, y = ytrain, nfolds = 10, alpha = 1)
```

```{r}
lassomodel$lambda.min

pred1 = predict(lassomodel, newx = xtest, s = "lambda.min")
sqrt(mean((pred1 - ytest)^2))
```

Training our elastic net model 
```{r}
elastic_net_model <- cv.glmnet(x = xtrain, y = ytrain, nfolds = 10, alpha = 0.5)
```

```{r}
elastic_net_model$lambda.min

pred1 = predict(elastic_net_model, newx = xtest, s = "lambda.min")
sqrt(mean((pred1 - ytest)^2))
```

Out of our 3 linear models, Lasso performed the best, with a RMSE of _______


2. K Nearest Neighbors(KNN) regression works by calculating the k nearest training set data points to the test point and predicting the target value by taking the average of their target values. KNN is sensitive to feature scaling, so we will need to scale the data. The reason behind this is for example, if one feature has ranges from 1-10 and another one has 1-10000, distance calcualtions will be biased and results will suffer as a result. KNN is also sensitive to the choice of k. To find the optimal value of k, we will perform k-fold cross validation. 
```{r}
xtrain
```

```{r}
set.seed(1)

dmy <- dummyVars(" ~ .", data = xtrain)
trsf <- data.frame(predict(dmy, newdata = xtrain))

print(trsf)



```

```{r}
# Train the final model using the best value of k and find the predictions
best_k <- knn.cvfit$bestTune$k
knn_predictions <- knn(train = xtrain_processed, test = xtest_processed, cl = ytrain, k = best_k)

# Calculate prediction error 
print(paste("RMSE: ", sqrt(mean((as.numeric(knn_predictions) - ytest)^2))))
```


3. Random Forest 
```{r}
rf_model <- randomForest(train_labels ~ ., data = as.data.frame(train_data))

rf_predictions <- predict(rf_model, newdata = as.data.frame(test_data))
```
4. SVM? does this count as a linear model 
5. Gradient Boosting Regressor 

## Open-Ended Question/Conclusion
A researcher is interested in estimating the original price of the cars in your dataset as if they were brand new. 

Since you are predicting prices without direct historical data for new cars, you may be extrapolating beyond the range of your training data, which can lead to inaccuracies. External factors such as changes in market demand, economic conditions, or new models being released can affect car prices but may not be captured in your model.

